{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paralelismo en Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia proporciona distintos mecanismos para paralelizar código. Algunas de las estrategias y desafíos para escribir algoritmos paralelos son los siguientes:  \n",
    "\n",
    "* Estrategias de paralelismo\n",
    "     * SIMD\n",
    "     * Multi-hilo\n",
    "     * Tareas\n",
    "     * Multiproceso\n",
    "         * Memoria compartida\n",
    "         * Memoria distribuida\n",
    "     * Programación de GPU\n",
    "\n",
    "* Desafíos de la computación paralela\n",
    "     * Orden de ejecución\n",
    "         * ejecución de fuera de orden de posibilidad\n",
    "         * acceso y mutación simultáneos\n",
    "     * Acceso y movimiento de datos\n",
    "     * Código de acceso y movimiento\n",
    "     * Adaptación adecuada de la estrategia de paralelismo a las capacidades de su máquina\n",
    "     * Hacer coincidir adecuadamente la estrategia de paralelismo con el problema en cuestión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es lo que está sucediendo con nuestras computadoras?\n",
    "\n",
    "![](https://raw.githubusercontent.com/JuliaComputing/JuliaAcademyData.jl/master/courses/Parallel_Computing/images/40-years-processor-trend.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lo difícil de la computación paralela\n",
    "   * No pensamos en paralelo\n",
    "   * Aprendemos a escribir y razonar sobre programas en serie.\n",
    "   * El deseo de paralelismo a menudo surge _después_ de haber escrito su algoritmo (¡y lo encontró demasiado lento!)\n",
    "\n",
    "## Resumen:\n",
    "   * Las arquitecturas computacionales actuales nos empujan hacia la programación paralela para un rendimiento máximo, ¡incluso si no estamos en un clúster!\n",
    "   * Pero es difícil diseñar buenos algoritmos paralelos\n",
    "   * Es difícil de expresar y razonar sobre esos algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SIMD: El paralelismo que puede (a veces) suceder automáticamente\n",
    "\n",
    "SIMD: Instrucción única, datos múltiples (Single Instruction Multiple Data)\n",
    "\n",
    "**Nota:** También llamado confusamente vectorización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura\n",
    "\n",
    "En lugar de calcular cuatro sumas secuencialmente:\n",
    "\n",
    "\\begin{align}\n",
    "x_1 + y_1 &\\rightarrow z_1 \\\\\n",
    "x_2 + y_2 &\\rightarrow z_2 \\\\\n",
    "x_3 + y_3 &\\rightarrow z_3 \\\\\n",
    "x_4 + y_4 &\\rightarrow z_4\n",
    "\\end{align}\n",
    "\n",
    "Procesadores modernos tienen unidades de procesamiento vectorial que pueden hacer lo anterior a la vez:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{cc}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "y_4\n",
    "\\end{array}\\right)\n",
    "\\rightarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "z_1 \\\\\n",
    "z_2 \\\\\n",
    "z_3 \\\\\n",
    "z_4\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se logra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(100_000)\n",
    "function simplesum(A)\n",
    "    result = zero(eltype(A))\n",
    "    for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "simplesum(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como muchos lenguajes de programación modernos, Julia utiliza la verificación de límites ([_boundchecking_](https://docs.julialang.org/en/v1/devdocs/boundscheck/)) para garantizar la seguridad del programa al acceder a arreglos.\n",
    "En bucles internos u otras situaciones críticas de rendimiento, es posible que se desee omitir estas comprobaciones de límites para mejorar el rendimiento en tiempo de ejecución.\n",
    "\n",
    "En consecuencia, Julia incluye la macro `@inbounds(...)` para decirle al compilador que omita dichas comprobaciones de límites dentro del bloque dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime simplesum($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿ese tiempo es bueno?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime sum($A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diseñamos una función más lenta que la suma prediseñada `sum()`, ¡y también estamos obteniendo una respuesta diferente! Veamos qué sucede con un flotante de 32 bits en lugar de uno de 64 bits. Cada elemento tiene la mitad del número de bits, por lo que también permite duplicar la longitud (para que el número total de bits procesados permanezca constante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A32 = rand(Float32, length(A)*2)\n",
    "@btime simplesum($A32)\n",
    "@btime sum($A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Eso es aun peor! ¿Que está pasando aqui? \n",
    "Estamos viendo múltiples diferencias en el desempeño: ¿quizás la suma incorporada de Julia está usando algún paralelismo?\n",
    "\n",
    "Intentemos usar SIMD nosotros mismos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function simdsum(A)\n",
    "    result = zero(eltype(A))\n",
    "    @simd for i in eachindex(A)\n",
    "        @inbounds result += A[i]\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "@btime simdsum($A)\n",
    "@btime simdsum($A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué hizo y por qué no siempre usamos (usa Julia pues) `@simd` para cada bucle **for** automáticamente?\n",
    "\n",
    "Veamos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplesum(A), simdsum(A), sum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplesum(A32), simdsum(A32), sum(A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué no son iguales?\n",
    "\n",
    "Sin `@simd`, Julia está haciendo _exactamente_ lo que le dijimos que hiciera: está tomando cada elemento de nuestro arreglo y lo agrega a una gran pila secuencialmente. Nuestra respuesta es más pequeña de lo que la \"suma\" incorporada de Julia cree que es: eso es porque, como la pila se hace más grande, comenzamos a perder las partes inferiores de cada elemento que estamos sumando, ¡y esas pequeñas pérdidas comienzan a acumularse!\n",
    "\n",
    "La macro `@simd` le dice a Julia que puede reorganizar las adiciones de punto flotante -\n",
    "incluso si cambiara la respuesta. Dependiendo de su CPU, esto puede llevar a 2x o 4x\n",
    "o incluso un paralelismo 8x. Básicamente, Julia está calculando sumas independientes para\n",
    "los índices pares y los índices impares simultáneamente:\n",
    "\n",
    "\\begin{align}\n",
    "odds &\\leftarrow 0 \\\\\n",
    "evens &\\leftarrow 0 \\\\\n",
    "\\text{loop}&\\ \\text{odd}\\ i: \\\\\n",
    "    &\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "\\leftarrow\n",
    "\\left(\\begin{array}{cc}\n",
    "odds \\\\\n",
    "evens\n",
    "\\end{array}\\right)\n",
    "+\n",
    "\\left(\\begin{array}{cc}\n",
    "x_{i} \\\\\n",
    "x_{i+1}\n",
    "\\end{array}\\right) \\\\\n",
    "total &\\leftarrow evens + odds\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "En muchos casos, Julia puede y sabe que un bucle for puede ser vectorizado (SIMD-ed) y aprovechará esto por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = rand(1:10, 100_000)\n",
    "@btime simplesum($B)\n",
    "@btime sum($B)\n",
    "B32 = rand(Int32(1):Int32(10), length(B)*2)\n",
    "@btime simplesum($B32)\n",
    "@btime simdsum($B32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo inspeccionamos que se está vectorizando?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm simdsum(A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ¿cuáles son los desafíos?:\n",
    "\n",
    "- El mayor obstáculo es que tienes que convencer a Julia y LLVM de que puede usar instrucciones SIMD para tu algoritmo dado. Eso no siempre es posible.\n",
    "- Hay muchas limitaciones de lo que se puede y no se puede vectorizar\n",
    "- Es necesario pensar en las consecuencias de reordenar su algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "SIMD:\n",
    "- Explota el paralelismo integrado en un procesador\n",
    "- Ideal para bucles internos pequeños (y estrechos)\n",
    "- A menudo ocurre automáticamente si tienes cuidado\n",
    "    - Sigue las [mejores prácticas de rendimiento](https://docs.julialang.org/en/v1/manual/performance-tips/)\n",
    "    - Usa `@inbounds` para cualquier acceso a un arreglo\n",
    "    - Evita ramas o llamadas a funciones\n",
    "- Dependiendo del procesador y los tipos involucrados, puede producir ganancias de 2-16x con una sobrecarga extraordinariamente pequeña\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
